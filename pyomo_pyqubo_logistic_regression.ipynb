{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "K4JnfBNJNIQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install condacolab\n",
        "!pip install -q condacolab\n",
        "\n",
        "# Import and install Conda using condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW-AVbjmNeda",
        "outputId": "a82cacb6-4d10-4e7d-9232-f98d13f40876"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:06\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pyomo and solvers from the conda-forge channel\n",
        "!conda install -c conda-forge pyomo ipopt coin-or-bonmin coincbc glpk -y > /dev/null 2>&1\n",
        "\n",
        "# Install IDAES\n",
        "!pip install -q idaes-pse --pre > /dev/null 2>&1\n",
        "\n",
        "# Install the IDAES solver binaries, including Couenne\n",
        "!idaes get-extensions --to /usr/local/bin > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "wrS5atoiNe3N"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Verify Pyomo installation\n",
        "pyomo_path = shutil.which(\"pyomo\")\n",
        "print(f\"Pyomo path: {pyomo_path}\")\n",
        "\n",
        "# Verify IPOPT installation\n",
        "ipopt_path = shutil.which(\"ipopt\")\n",
        "print(f\"IPOPT path: {ipopt_path}\")\n",
        "\n",
        "# Verify Bonmin installation\n",
        "bonmin_path = shutil.which(\"bonmin\")\n",
        "print(f\"Bonmin path: {bonmin_path}\")\n",
        "\n",
        "# Verify CBC installation\n",
        "cbc_path = shutil.which(\"cbc\")\n",
        "print(f\"CBC path: {cbc_path}\")\n",
        "\n",
        "# Verify GLPK installation\n",
        "glpk_path = shutil.which(\"glpsol\")\n",
        "print(f\"GLPK path: {glpk_path}\")\n",
        "\n",
        "# Verify Couenne installation\n",
        "couenne_path = shutil.which(\"couenne\")\n",
        "print(f\"Couenne path: {couenne_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5K2YGjzNk5O",
        "outputId": "70714f7e-fe00-4224-daad-3bf8c6ff6e3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pyomo path: /usr/local/bin/pyomo\n",
            "IPOPT path: /usr/local/bin/ipopt\n",
            "Bonmin path: /usr/local/bin/bonmin\n",
            "CBC path: /usr/local/bin/cbc\n",
            "GLPK path: /usr/local/bin/glpsol\n",
            "Couenne path: /usr/local/bin/couenne\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Data"
      ],
      "metadata": {
        "id": "CoFHlGW_ODjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scikit-learn statsmodels"
      ],
      "metadata": {
        "id": "z1NibBQ05aVm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "import statsmodels.api as sm\n",
        "import pyomo.environ as pyo"
      ],
      "metadata": {
        "id": "YEcYvVWhOJwn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "dzaOzGb6OI-K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SKLearn & StatsModels"
      ],
      "metadata": {
        "id": "LzcdYq64_lVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression with scikit-learn\n",
        "sklearn_model = LogisticRegression(solver='lbfgs')\n",
        "sklearn_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_sklearn = sklearn_model.predict(X_test)\n",
        "y_pred_proba_sklearn = sklearn_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "log_loss_sklearn = log_loss(y_test, y_pred_proba_sklearn)\n",
        "print(f\"Accuracy (scikit-learn): {accuracy_sklearn:.4f}\")\n",
        "print(f\"Log Loss (scikit-learn): {log_loss_sklearn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoPaXj42_dIM",
        "outputId": "3bb3a896-8140-43b8-86f4-a6b4e7a242e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (scikit-learn): 0.8467\n",
            "Log Loss (scikit-learn): 0.3566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression with statsmodels\n",
        "X_train_sm = sm.add_constant(X_train)  # Adding intercept term\n",
        "X_test_sm = sm.add_constant(X_test)\n",
        "\n",
        "statsmodels_model = sm.Logit(y_train, X_train_sm).fit()\n",
        "\n",
        "y_pred_proba_sm = statsmodels_model.predict(X_test_sm)\n",
        "y_pred_sm = (y_pred_proba_sm >= 0.5).astype(int)\n",
        "\n",
        "accuracy_sm = accuracy_score(y_test, y_pred_sm)\n",
        "log_loss_sm = log_loss(y_test, y_pred_proba_sm)\n",
        "print(f\"\\nAccuracy (statsmodels): {accuracy_sm:.4f}\")\n",
        "print(f\"Log Loss (statsmodels): {log_loss_sm:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeMrFmSO_p44",
        "outputId": "830aa267-d05a-483e-ce09-25dd4011f9fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.322850\n",
            "         Iterations 8\n",
            "\n",
            "Accuracy (statsmodels): 0.8400\n",
            "Log Loss (statsmodels): 0.3576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pyomo Solution"
      ],
      "metadata": {
        "id": "8CrPASYwOP9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegressionPyomo:\n",
        "    \"\"\"\n",
        "    Logistic Regression model using Pyomo for Maximum Likelihood Estimation (MLE).\n",
        "\n",
        "    Attributes:\n",
        "    -----------\n",
        "    X : np.ndarray\n",
        "        The feature matrix.\n",
        "    y : np.ndarray\n",
        "        The target vector.\n",
        "    beta : np.ndarray\n",
        "        The estimated coefficients after fitting the model.\n",
        "    model : pyomo.ConcreteModel\n",
        "        The Pyomo optimization model.\n",
        "\n",
        "    Methods:\n",
        "    --------\n",
        "    fit(solver_name='ipopt'):\n",
        "        Fits the logistic regression model using the selected Pyomo solver.\n",
        "    predict_proba(X_new):\n",
        "        Predicts probabilities for new data.\n",
        "    predict(X_new):\n",
        "        Predicts binary class labels for new data.\n",
        "    evaluate(X_test, y_test):\n",
        "        Evaluates the model on test data, returning accuracy and log loss.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        \"\"\"\n",
        "        Initializes the LogisticRegressionPyomo model with the provided data.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : np.ndarray\n",
        "            The feature matrix.\n",
        "        y : np.ndarray\n",
        "            The target vector.\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.model = None\n",
        "        self.beta = None\n",
        "\n",
        "    def fit(self, solver_name='ipopt'):\n",
        "        \"\"\"\n",
        "        Fits the logistic regression model using Pyomo for Maximum Likelihood Estimation (MLE).\n",
        "        The user can choose the solver.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        solver_name : str, optional (default='ipopt')\n",
        "            The name of the solver to use (e.g., 'ipopt', 'cbc', 'glpk').\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        beta : np.ndarray\n",
        "            The estimated coefficients.\n",
        "        \"\"\"\n",
        "        n_samples, n_features = self.X.shape\n",
        "\n",
        "        # Create a Pyomo model\n",
        "        self.model = pyo.ConcreteModel()\n",
        "\n",
        "        # Define variables (beta coefficients) for each feature\n",
        "        self.model.beta = pyo.Var(range(n_features), domain=pyo.Reals, initialize=0.0)\n",
        "\n",
        "        # Objective: Negative Log-Likelihood\n",
        "        def neg_log_likelihood_rule(m):\n",
        "            neg_log_likelihood = 0\n",
        "            for i in range(n_samples):\n",
        "                z = sum(m.beta[j] * self.X[i, j] for j in range(n_features))\n",
        "                p = 1 / (1 + pyo.exp(-z))  # Sigmoid function using Pyomo's exp\n",
        "                epsilon = 1e-8  # To prevent log(0)\n",
        "                neg_log_likelihood += -self.y[i] * pyo.log(p + epsilon) - (1 - self.y[i]) * pyo.log(1 - p + epsilon)\n",
        "            return neg_log_likelihood\n",
        "\n",
        "        # Minimize the negative log-likelihood\n",
        "        self.model.obj = pyo.Objective(rule=neg_log_likelihood_rule, sense=pyo.minimize)\n",
        "\n",
        "        # Use the user-specified solver\n",
        "        solver = pyo.SolverFactory(solver_name)\n",
        "\n",
        "        # Check if the solver is available\n",
        "        if not solver.available():\n",
        "            raise ValueError(f\"Solver '{solver_name}' is not available. Please ensure it is installed.\")\n",
        "\n",
        "        # Solve the optimization problem\n",
        "        result = solver.solve(self.model)\n",
        "\n",
        "        # Store the estimated coefficients\n",
        "        self.beta = np.array([pyo.value(self.model.beta[j]) for j in range(n_features)])\n",
        "\n",
        "        return self.beta\n",
        "\n",
        "    def predict_proba(self, X_new):\n",
        "        \"\"\"\n",
        "        Predicts probabilities for new data.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X_new : np.ndarray\n",
        "            The new feature matrix.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        np.ndarray\n",
        "            The predicted probabilities for each instance in X_new.\n",
        "        \"\"\"\n",
        "        z = np.dot(X_new, self.beta)\n",
        "        return 1 / (1 + np.exp(-z))  # Sigmoid using NumPy for prediction\n",
        "\n",
        "    def predict(self, X_new):\n",
        "        \"\"\"\n",
        "        Predicts binary class labels for new data.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X_new : np.ndarray\n",
        "            The new feature matrix.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        np.ndarray\n",
        "            The predicted binary class labels.\n",
        "        \"\"\"\n",
        "        return (self.predict_proba(X_new) >= 0.5).astype(int)\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Evaluates the model on test data, returning accuracy and log loss.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X_test : np.ndarray\n",
        "            The test feature matrix.\n",
        "        y_test : np.ndarray\n",
        "            The test target vector.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        tuple\n",
        "            A tuple containing the accuracy and log loss on the test data.\n",
        "        \"\"\"\n",
        "        y_pred_proba = self.predict_proba(X_test)\n",
        "        y_pred = self.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        log_loss_val = log_loss(y_test, y_pred_proba)\n",
        "        return accuracy, log_loss_val"
      ],
      "metadata": {
        "id": "f_zZB-vkOmGZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Logistic Regression model using Pyomo\n",
        "logreg_pyomo = LogisticRegressionPyomo(X_train, y_train)\n",
        "\n",
        "# Fit the model using IPOPT solver (default)\n",
        "beta_ipopt = logreg_pyomo.fit(solver_name='ipopt')\n",
        "print(f\"Estimated Coefficients (IPOPT):\\n{beta_ipopt}\")\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_ipopt, log_loss_ipopt = logreg_pyomo.evaluate(X_test, y_test)\n",
        "print(f\"\\nAccuracy (IPOPT): {accuracy_ipopt:.4f}\")\n",
        "print(f\"Log Loss (IPOPT): {log_loss_ipopt:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95A6SbtCOr3s",
        "outputId": "a1a78bbb-e360-4687-a8c8-1d91279e4ebe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated Coefficients (IPOPT):\n",
            "[-0.50881399  0.11611761 -1.19623329  0.08706355 -0.07761979 -0.29737023\n",
            "  1.685782   -0.0079884  -1.09529722  0.06244599]\n",
            "\n",
            "Accuracy (IPOPT): 0.8400\n",
            "Log Loss (IPOPT): 0.3557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Logistic Regression model using Pyomo\n",
        "logreg_pyomo = LogisticRegressionPyomo(X_train, y_train)\n",
        "\n",
        "# Fit the model using Bonmin solver\n",
        "beta_bonmin = logreg_pyomo.fit(solver_name='bonmin')\n",
        "print(f\"Estimated Coefficients (Bonmin):\\n{beta_bonmin}\")\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_bonmin, log_loss_bonmin = logreg_pyomo.evaluate(X_test, y_test)\n",
        "print(f\"\\nAccuracy (Bonmin): {accuracy_bonmin:.4f}\")\n",
        "print(f\"Log Loss (Bonmin): {log_loss_bonmin:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJlbXLkAOzAP",
        "outputId": "7bc86af3-b4ec-4e01-b8e8-22bdabe27afc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated Coefficients (Bonmin):\n",
            "[-0.50881399  0.11611761 -1.19623329  0.08706355 -0.07761979 -0.29737023\n",
            "  1.685782   -0.0079884  -1.09529722  0.06244599]\n",
            "\n",
            "Accuracy (Bonmin): 0.8400\n",
            "Log Loss (Bonmin): 0.3557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyQUBO Solution"
      ],
      "metadata": {
        "id": "Rmm1dh1SY2Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyqubo dimod"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66dzB3UpY5Xn",
        "outputId": "5f66a5fc-5623-4b8d-a9ed-baff1d5ea91c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyqubo import Array, Constraint, Placeholder, solve_qubo\n",
        "import dimod\n",
        "from neal import SimulatedAnnealingSampler"
      ],
      "metadata": {
        "id": "JfR7wqyPY-f3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegressionQUBO:\n",
        "    \"\"\"\n",
        "    Logistic Regression model using QUBO formulation optimized with a Simulated Annealing Sampler.\n",
        "\n",
        "    Attributes:\n",
        "    -----------\n",
        "    X : np.ndarray\n",
        "        The feature matrix.\n",
        "    y : np.ndarray\n",
        "        The target vector.\n",
        "    n_bits : int\n",
        "        The number of bits used to represent each weight.\n",
        "\n",
        "    Methods:\n",
        "    --------\n",
        "    fit(lam=10):\n",
        "        Fits the logistic regression model by minimizing the QUBO objective.\n",
        "    predict_proba(X_new):\n",
        "        Predicts probabilities for new data.\n",
        "    predict(X_new):\n",
        "        Predicts binary class labels for new data.\n",
        "    evaluate(X_test, y_test):\n",
        "        Evaluates the model on test data, returning accuracy and log loss.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X, y, n_bits=4):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.n_bits = n_bits\n",
        "        self.beta = None  # Binary weights for the model\n",
        "\n",
        "    def fit(self, lam=10):\n",
        "        \"\"\"\n",
        "        Fits the logistic regression model by minimizing the QUBO objective using simulated annealing.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        lam : float, optional (default=10)\n",
        "            Regularization parameter to control the tradeoff between fitting and constraint satisfaction.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        beta : np.ndarray\n",
        "            The estimated coefficients.\n",
        "        \"\"\"\n",
        "        n_samples, n_features = self.X.shape\n",
        "\n",
        "        # Define binary weights for each feature\n",
        "        weight_bits = Array.create('w', shape=(n_features, self.n_bits), vartype='BINARY')\n",
        "\n",
        "        # QUBO objective for logistic regression\n",
        "        qubo_objective = 0\n",
        "        for i in range(n_samples):\n",
        "            # Approximate z = X[i] . beta using binary weights\n",
        "            z_i = sum((2**k) * self.X[i, j] * weight_bits[j, k] for j in range(n_features) for k in range(self.n_bits))\n",
        "\n",
        "            # Logistic loss approximation (using a linear penalty instead of sigmoid)\n",
        "            if self.y[i] == 1:\n",
        "                qubo_objective += (1 - z_i) ** 2  # Penalty for positive class\n",
        "            else:\n",
        "                qubo_objective += (z_i) ** 2  # Penalty for negative class\n",
        "\n",
        "        # Add constraints to ensure binary weights represent real-valued coefficients\n",
        "        qubo_objective += Placeholder('lambda') * sum(\n",
        "            (sum(weight_bits[j, k] for k in range(self.n_bits)) - 1) ** 2\n",
        "            for j in range(n_features)\n",
        "        )\n",
        "\n",
        "        # Compile the QUBO model\n",
        "        compiled_qubo = qubo_objective.compile()\n",
        "        qubo, offset = compiled_qubo.to_qubo(feed_dict={'lambda': lam})\n",
        "\n",
        "        # Use the Simulated Annealing Sampler to solve the QUBO problem\n",
        "        sampler = SimulatedAnnealingSampler()\n",
        "        response = sampler.sample_qubo(qubo, num_reads=100)\n",
        "        best_solution = response.first.sample\n",
        "\n",
        "        # Extract the binary weights from the solution\n",
        "        self.beta = np.array([sum((2**k) * best_solution[f'w[{j}][{k}]'] for k in range(self.n_bits))\n",
        "                              for j in range(n_features)])\n",
        "\n",
        "        return self.beta\n",
        "\n",
        "    def predict_proba(self, X_new):\n",
        "        \"\"\"\n",
        "        Predicts probabilities for new data.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X_new : np.ndarray\n",
        "            The new feature matrix.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        np.ndarray\n",
        "            The predicted probabilities for each instance in X_new.\n",
        "        \"\"\"\n",
        "        z = np.dot(X_new, self.beta)\n",
        "        return 1 / (1 + np.exp(-z))  # Sigmoid using NumPy for prediction\n",
        "\n",
        "    def predict(self, X_new):\n",
        "        \"\"\"\n",
        "        Predicts binary class labels for new data.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X_new : np.ndarray\n",
        "            The new feature matrix.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        np.ndarray\n",
        "            The predicted binary class labels.\n",
        "        \"\"\"\n",
        "        return (self.predict_proba(X_new) >= 0.5).astype(int)\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Evaluates the model on test data, returning accuracy and log loss.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X_test : np.ndarray\n",
        "            The test feature matrix.\n",
        "        y_test : np.ndarray\n",
        "            The test target vector.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        tuple\n",
        "            A tuple containing the accuracy and log loss on the test data.\n",
        "        \"\"\"\n",
        "        y_pred_proba = self.predict_proba(X_test)\n",
        "        y_pred = self.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        log_loss_val = log_loss(y_test, y_pred_proba)\n",
        "        return accuracy, log_loss_val"
      ],
      "metadata": {
        "id": "d6xBhgVqZCEJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Logistic Regression model using QUBO\n",
        "logreg_qubo = LogisticRegressionQUBO(X_train, y_train, n_bits=4)\n",
        "\n",
        "# Fit the model\n",
        "beta_qubo = logreg_qubo.fit()\n",
        "print(f\"Estimated Coefficients (QUBO):\\n{beta_qubo}\")\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_qubo, log_loss_qubo = logreg_qubo.evaluate(X_test, y_test)\n",
        "print(f\"\\nAccuracy (QUBO): {accuracy_qubo:.4f}\")\n",
        "print(f\"Log Loss (QUBO): {log_loss_qubo:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT3ZrLjZZEzS",
        "outputId": "cda29614-17e3-4c68-8e1d-8debf8e12516"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated Coefficients (QUBO):\n",
            "[1 0 1 0 0 0 2 0 1 0]\n",
            "\n",
            "Accuracy (QUBO): 0.8500\n",
            "Log Loss (QUBO): 0.5763\n"
          ]
        }
      ]
    }
  ]
}